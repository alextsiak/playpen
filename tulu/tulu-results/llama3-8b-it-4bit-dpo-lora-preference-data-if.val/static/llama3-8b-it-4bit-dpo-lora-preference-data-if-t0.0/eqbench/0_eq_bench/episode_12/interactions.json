{
  "meta": {
    "game_name": "eqbench",
    "experiment_name": "eq_bench",
    "game_id": 83,
    "results_folder": "llama3-8b-it-4bit-dpo-lora-preference-data-if-t0.0",
    "clem_version": "3.2.1"
  },
  "player_models": {
    "0": {
      "model_name": "llama3-8b-it-4bit-dpo-lora-preference-data-if",
      "backend": "huggingface_local",
      "context_size": "8192",
      "huggingface_id": "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
      "languages": [
        "en",
        "de",
        "fr",
        "it",
        "pt",
        "hi",
        "es",
        "th"
      ],
      "license": {
        "name": "Meta (with LoRA)",
        "url": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/LICENSE"
      },
      "lookup_source": "/home/users/rzorin/playpen/model_registry.json",
      "model_config": {
        "peft_model": "/home/users/rzorin/playpen/8b-instruct-4bit-dpo-lora-preference-data-if",
        "premade_chat_template": true,
        "eos_to_cull": "<\\|eot_id\\|>"
      },
      "open_weight": true,
      "parameters": "8B",
      "release_date": "2025-06-18",
      "tokenizer_kwargs": {
        "use_fast": true
      }
    }
  },
  "players": {
    "GM": {
      "game_role": "Game Master",
      "model_name": "programmatic"
    },
    "Player 1": {
      "game_role": "Answerer",
      "model_name": "llama3-8b-it-4bit-dpo-lora-preference-data-if"
    }
  },
  "turns": [
    [
      {
        "from": "GM",
        "to": "Player 1",
        "timestamp": "2025-08-21T20:09:09.086691",
        "action": {
          "type": "send message",
          "content": "\nYour task is to predict the likely emotional responses of a character in this dialogue:\n\nCharlie: You're too green for this, Ruiz.\nMari: And you're too washed up, Redburn.\nCharlie: I've been on this beat longer than you've been alive, kid.\nMari: And yet, here we are, stuck on the same case. Seems like experience isn't everything.\nCharlie: Don't get smart with me, Mari.\nMari: Someone has to be the smart one here.\nCharlie: You think I don't know what you're doing? Trying to prove yourself, make a name?\nMari: Better than drinking myself into oblivion.\nCharlie: That's a low blow, Ruiz.\n[End dialogue]\n\nAt the end of this dialogue, Mari would feel...\nDefensive\nUnapologetic\nGuilty\nTriumphant\n\nGive each of these possible emotions a score from 0-10 for the relative intensity that they are likely to be feeling each.\n\nYou must output in the following format, including headings (of course, you should give your own scores), with no additional commentary:\n\nDefensive: <score>\nUnapologetic: <score>\nGuilty: <score>\nTriumphant: <score>\n\n\n[End of answer]\n\nRemember: zero is a valid score, meaning they are likely not feeling that emotion. You must score at least one emotion > 0.\n\nYour answer:\n",
          "label": "context"
        }
      },
      {
        "from": "Player 1",
        "to": "GM",
        "timestamp": "2025-08-21T20:09:11.435549",
        "action": {
          "type": "get message",
          "content": "Defensive: 6\nUnapologetic: 9\nGuilty: 0\nTriumphant: 8",
          "label": "response"
        }
      },
      {
        "from": "GM",
        "to": "GM",
        "timestamp": "2025-08-21T20:09:11.435644",
        "action": {
          "type": "parsed",
          "content": "Defensive: 6\nUnapologetic: 9\nGuilty: 0\nTriumphant: 8"
        }
      },
      {
        "from": "GM",
        "to": "GM",
        "timestamp": "2025-08-21T20:09:11.435667",
        "action": {
          "type": "target",
          "content": "Defensive: 4\nUnapologetic: 8\nGuilty: 0\nTriumphant: 6"
        }
      },
      {
        "from": "GM",
        "to": "GM",
        "timestamp": "2025-08-21T20:09:11.435679",
        "action": {
          "type": "not exact match",
          "content": "game_result = LOSE"
        }
      }
    ]
  ],
  "Parsed Response": {
    "Defensive": 6,
    "Unapologetic": 9,
    "Guilty": 0,
    "Triumphant": 8
  },
  "Aborted": 0,
  "Lose": 1,
  "Success": 0,
  "Request Count": 1,
  "Parsed Request Count": 1,
  "Violated Request Count": 0
}